[core]
airflow_home = /usr/local/airflow
executor = CeleryExecutor
default_timezone = utc
dags_folder = /usr/local/airflow/dags
load_examples = False
fernet_key = ${FERNET_KEY}
secret_key = ${SECRET_KEY}

[database]
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres:5432/airflow

[webserver]
web_server_port = 8080
web_server_log_level = info
web_server_host = 0.0.0.0
expose_config = False

[logging]
base_log_folder = /usr/local/airflow/logs
remote_logging = True
remote_log_conn_id = MyS3Conn
remote_base_log_folder = s3://airflow-etl-data/logs

[scheduler]
dags_are_paused_at_creation = False
catchup_by_default = True
max_threads = 2
dag_dir_list_interval = 60

[celery]
broker_url = redis://redis:6379/0
result_backend = db+postgresql://airflow:airflow@postgres:5432/airflow
worker_concurrency = 16
worker_log_server_port = 8793
worker_ping_interval = 30
flower_host = 0.0.0.0
flower_port = 5555
worker_autoscale = 16,4

[worker]
default_celery_task_retries = 3
celery_retry_delay = 300